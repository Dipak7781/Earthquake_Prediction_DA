{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-09-03T17:34:42.816435Z","iopub.status.busy":"2024-09-03T17:34:42.815948Z","iopub.status.idle":"2024-09-03T17:34:45.424112Z","shell.execute_reply":"2024-09-03T17:34:45.422642Z","shell.execute_reply.started":"2024-09-03T17:34:42.816389Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.metrics import mean_squared_error\n","from sklearn.model_selection import KFold, StratifiedKFold, RepeatedKFold, train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-09-03T17:34:45.428076Z","iopub.status.busy":"2024-09-03T17:34:45.427237Z","iopub.status.idle":"2024-09-03T17:34:46.648623Z","shell.execute_reply":"2024-09-03T17:34:46.645100Z","shell.execute_reply.started":"2024-09-03T17:34:45.428016Z"},"trusted":true},"outputs":[],"source":["data = pd.read_csv('../input/LANL-Earthquake-Prediction/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure':np.float64})\n","\n","train, test = train_test_split(data, test_size=0.3, shuffle=False) # Split data into 70% training and 30% test\n","train.head(10)\n","test.head(10)\n","\n","del data"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.649543Z","iopub.status.idle":"2024-09-03T17:34:46.650017Z","shell.execute_reply":"2024-09-03T17:34:46.649798Z","shell.execute_reply.started":"2024-09-03T17:34:46.649777Z"},"trusted":true},"outputs":[],"source":["print(train.shape)\n","print(test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.652217Z","iopub.status.idle":"2024-09-03T17:34:46.652880Z","shell.execute_reply":"2024-09-03T17:34:46.652567Z","shell.execute_reply.started":"2024-09-03T17:34:46.652536Z"},"trusted":true},"outputs":[],"source":["acoustic_data_ = train['acoustic_data'].values[::75]  \n","time_to_failure_ = train['time_to_failure'].values[::75]\n","\n","fig, ax1 = plt.subplots(figsize=(16, 8))\n","plt.title(\"Trends of acoustic_data and time_to_failure. 2% of data (sampled)\")\n","plt.plot(acoustic_data_, color='b')\n","ax1.set_ylabel('acoustic_data', color='b')\n","plt.legend(['acoustic_data'])\n","ax2 = ax1.twinx()\n","plt.plot(time_to_failure_, color='g')\n","ax2.set_ylabel('time_to_failure', color='g')\n","plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n","plt.grid(False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.655549Z","iopub.status.idle":"2024-09-03T17:34:46.656195Z","shell.execute_reply":"2024-09-03T17:34:46.655913Z","shell.execute_reply.started":"2024-09-03T17:34:46.655880Z"},"trusted":true},"outputs":[],"source":["acoustic_data_ = train['acoustic_data'].values[:6291455]  \n","time_to_failure_ = train['time_to_failure'].values[:6291455]\n","\n","fig, ax1 = plt.subplots(figsize=(16, 8))\n","plt.title(\"More detailed acoustic data (1% of data)\")\n","plt.plot(acoustic_data_, color='b')\n","ax1.set_ylabel('acoustic_data', color='b')\n","plt.legend(['acoustic_data'])\n","ax2 = ax1.twinx()\n","plt.plot(time_to_failure_, color='g')\n","ax2.set_ylabel('time_to_failure', color='g')\n","plt.legend(['time_to_failure'], loc=(0.875, 0.9))\n","plt.grid(False)\n","\n","del acoustic_data_\n","del time_to_failure_"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.657703Z","iopub.status.idle":"2024-09-03T17:34:46.658340Z","shell.execute_reply":"2024-09-03T17:34:46.658063Z","shell.execute_reply.started":"2024-09-03T17:34:46.658032Z"},"trusted":true},"outputs":[],"source":["rows = 150000 # Amount of rows per segment\n","train_segments = int(np.floor(train.shape[0] / rows)) # Amount of segments in dataset\n","print(\"Amount of segments: \", train_segments)\n","\n","x_train = pd.DataFrame(index=range(train_segments), dtype=np.float64, columns=['mean', 'std', 'min', 'max', 'skew', 'kurtosis', 'Imean', 'Rmean', 'Imin', 'Rmin', 'Imax', 'Rmax', 'max_to_min'])\n","y_train = pd.DataFrame(index=range(train_segments), dtype=np.float64, columns=['time_to_failure'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.660442Z","iopub.status.idle":"2024-09-03T17:34:46.661058Z","shell.execute_reply":"2024-09-03T17:34:46.660763Z","shell.execute_reply.started":"2024-09-03T17:34:46.660734Z"},"trusted":true},"outputs":[],"source":["def extract_features(seg_id, seg, X):\n","    values = pd.Series(seg['acoustic_data'].values)\n","    values_fft = np.fft.fft(values)\n","    values_real = np.real(values_fft)\n","    values_imag = np.imag(values_fft)\n","    \n","    X.loc[seg_id, 'mean'] = values.mean()\n","    X.loc[seg_id, 'std'] = values.std()\n","    X.loc[seg_id, 'min'] = values.min()\n","    X.loc[seg_id, 'max'] = values.max()\n","    X.loc[seg_id, 'skew'] = values.skew()\n","    X.loc[seg_id, 'kurtosis'] = values.kurt()\n","    \n","    X.loc[seg_id, 'Imean'] = values_imag.mean()\n","    X.loc[seg_id, 'Rmean'] = values_real.mean()\n","    \n","    X.loc[seg_id, 'Imin'] = values_imag.min()\n","    X.loc[seg_id, 'Rmin'] = values_real.min()\n","    \n","    X.loc[seg_id, 'Imax'] = values_imag.max()\n","    X.loc[seg_id, 'Rmax'] = values_real.max()\n","    \n","    X.loc[seg_id, 'max_to_min'] = values.max() - values.min()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.662672Z","iopub.status.idle":"2024-09-03T17:34:46.663274Z","shell.execute_reply":"2024-09-03T17:34:46.663007Z","shell.execute_reply.started":"2024-09-03T17:34:46.662979Z"},"trusted":true},"outputs":[],"source":["for seg_id in range(train_segments):\n","    seg = train.iloc[seg_id * rows : seg_id * rows + rows] # Select segment data points\n","    extract_features(seg_id, seg, x_train) # Extract the features for this segment\n","    y_train.loc[seg_id, 'time_to_failure'] = seg['time_to_failure'].values[-1] # Copy corresponding output (time_to_failure)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.665059Z","iopub.status.idle":"2024-09-03T17:34:46.665711Z","shell.execute_reply":"2024-09-03T17:34:46.665383Z","shell.execute_reply.started":"2024-09-03T17:34:46.665352Z"},"trusted":true},"outputs":[],"source":["print(\"Output shape: \", x_train.shape)\n","x_train.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.667606Z","iopub.status.idle":"2024-09-03T17:34:46.668227Z","shell.execute_reply":"2024-09-03T17:34:46.667946Z","shell.execute_reply.started":"2024-09-03T17:34:46.667917Z"},"trusted":true},"outputs":[],"source":["test_segments = int(np.floor(test.shape[0] / rows))\n","print(\"Amount of test segments: \", test_segments)\n","\n","x_test = pd.DataFrame(index=range(test_segments), dtype=np.float64, columns=['mean', 'std', 'min', 'max', 'skew', 'kurtosis', 'Imean', 'Rmean', 'Imin', 'Rmin', 'Imax', 'Rmax', 'max_to_min'])\n","y_test = pd.DataFrame(index=range(test_segments), dtype=np.float64, columns=['time_to_failure'])\n","\n","for seg_id in range(test_segments):\n","    seg = test.iloc[seg_id * rows : seg_id * rows + rows]\n","    extract_features(seg_id, seg, x_test)\n","    y_test.loc[seg_id, 'time_to_failure'] = seg['time_to_failure'].values[-1]\n","\n","print(\"Test output shape: \", x_test.shape)\n","x_test.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.669796Z","iopub.status.idle":"2024-09-03T17:34:46.670445Z","shell.execute_reply":"2024-09-03T17:34:46.670171Z","shell.execute_reply.started":"2024-09-03T17:34:46.670114Z"},"trusted":true},"outputs":[],"source":["train_scaler = StandardScaler().fit(x_train)\n","test_scaler = StandardScaler().fit(x_test)\n","\n","x_train_scaled = train_scaler.transform(x_train)\n","x_test_scaled = test_scaler.transform(x_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.672083Z","iopub.status.idle":"2024-09-03T17:34:46.672672Z","shell.execute_reply":"2024-09-03T17:34:46.672396Z","shell.execute_reply.started":"2024-09-03T17:34:46.672367Z"},"trusted":true},"outputs":[],"source":["del train\n","del test"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.674390Z","iopub.status.idle":"2024-09-03T17:34:46.675026Z","shell.execute_reply":"2024-09-03T17:34:46.674733Z","shell.execute_reply.started":"2024-09-03T17:34:46.674703Z"},"trusted":true},"outputs":[],"source":["def train_model(x_train, y_train, x_test, y_test, model):\n","    model.fit(x_train, y_train.values.flatten())\n","    \n","    train_pred = model.predict(x_train)\n","    test_pred = model.predict(x_test)\n","    \n","    train_score = mean_squared_error(y_train, train_pred) # Calculate MSE for training data\n","    test_score = mean_squared_error(y_test, test_pred) # Calculate MSE for test data\n","    \n","    print(\"Train MSE: \", train_score)\n","    print(\"Test MSE: \", test_score)\n","    \n","    plt.scatter(y_train.values.flatten(), train_pred, label=\"Train\")\n","    plt.scatter(y_test.values.flatten(), test_pred, label=\"Test\")\n","    plt.plot([(0, 0), (16, 16)], [(0, 0), (16, 16)], color='g')\n","    plt.xlim([0, 16])\n","    plt.ylim([0, 16])\n","    plt.xlabel(\"Expected\")\n","    plt.ylabel(\"Actual\")\n","    plt.legend()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.680049Z","iopub.status.idle":"2024-09-03T17:34:46.680898Z","shell.execute_reply":"2024-09-03T17:34:46.680486Z","shell.execute_reply.started":"2024-09-03T17:34:46.680407Z"},"trusted":true},"outputs":[],"source":["train_model(x_train_scaled, y_train, x_test_scaled, y_test, LinearRegression())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.682745Z","iopub.status.idle":"2024-09-03T17:34:46.683434Z","shell.execute_reply":"2024-09-03T17:34:46.683106Z","shell.execute_reply.started":"2024-09-03T17:34:46.683074Z"},"trusted":true},"outputs":[],"source":["train_model(x_train_scaled, y_train, x_test_scaled, y_test, RandomForestRegressor())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.status.busy":"2024-09-03T17:34:46.686290Z","iopub.status.idle":"2024-09-03T17:34:46.686934Z","shell.execute_reply":"2024-09-03T17:34:46.686637Z","shell.execute_reply.started":"2024-09-03T17:34:46.686591Z"},"trusted":true},"outputs":[],"source":["submission = pd.read_csv('../input/LANL-Earthquake-Prediction/sample_submission.csv', index_col='seg_id')\n","submission_x_test = pd.DataFrame(columns=x_train.columns, dtype=np.float64, index=submission.index)\n","\n","for seg_id in submission_x_test.index:\n","    seg = pd.read_csv('../input/LANL-Earthquake-Prediction/test/' + seg_id + '.csv')\n","    extract_features(seg_id, seg, submission_x_test)\n","\n","submission_x_test_scaled = train_scaler.transform(submission_x_test)\n","\n","model = RandomForestRegressor()\n","model.fit(x_train_scaled, y_train.values.flatten())\n","submission['time_to_failure'] = model.predict(submission_x_test_scaled)\n","submission.to_csv('submission.csv', index=True)\n","print(submission)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30761,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
